env                     = "dev"
account_id              = "000000000000"
datalake_bucket         = "datalake"
source_bucket_name      = "dev-datalake"
artifact_bucket         = "dev-de-assets"
artifact_prefix         = "deDataHub"
artifact_encryption_key = "arn:aws:kms:us-east-1:000000000000:key/75367033-46ff-4c29-91b2-0df67b73637d"
branch                  = "develop"
parameter_store         = "EnvironmentStage"
secret                  = "dev/DataHub/Glue_svc"
data_hub_connection_secret = "dev/DataHub/Glue_svc"
lambda_function_name     = "DataHubS3Trigger"
lambda_function_name_api = "DataHubAPIHandler"
lambda_function_name_sch = "DataHubScheduler"
api_method_post_issue    = "deDataHubAPI"
datahub_function_name    = "deUtils" # This is the python code base that owns the data hub class.
mssql_layer             = "arn:aws:lambda:us-east-1:000000000000:layer:pymssql39:1"
boto_layer              = "arn:aws:lambda:us-east-1:000000000000:layer:boto3-layer:1"
datahub_layer           = "arn:aws:lambda:us-east-1:000000000000:layer:Python39-deDataHub:latest"
#deUtils_layer           = "arn:aws:lambda:us-east-1:000000000000:layer:Python39-deUtils:latest"
                           
timeout_seconds         = 120
db_dh = "adw"
db_dw = "adw"
sqs_pg_dw_name = "deDWPostingGroup.fifo"
sqs_pg_dlq_name = "deDWPostingGroup-dlq.fifo"
fifo = true
ftp_domain = "S3"
subnet_ids = ["subnet-00000000"]
security_group_ids = ["sg-000000000","sg-000000000","sg-00000000"]
